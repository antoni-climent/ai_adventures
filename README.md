# ğŸ§  AI Adventures ğŸš€ğŸ¤–ğŸ”

This repo contains my hands-on implementations of various AI algorithms, created to deepen my understanding of fundamental concepts. ğŸ’¡ The code prioritizes clarity and minimizes external dependencies, making these implementations both educational and accessible.

## ğŸ“š Projects

### ğŸ”¹ Perceptron ([perceptron.py](perceptron.py))

ğŸ§® This project implements a simple perceptron inspired by Andrej Karpathy's [Micrograd](https://github.com/karpathy/micrograd/tree/master). 

âœ¨ It features automatic gradient computation for various operations:
- â• Basic math: addition, subtraction, negation, multiplication, division, power
- ğŸ“ˆ Activation functions: tanh, ReLU
- ğŸ”„ Other functions: exponential

ğŸ§© The Perceptron class uses a tanh activation function and is trained with backpropagation on a dataset generated from the logical expression $AB + A\overline{B}$.

### ğŸ”¹ Gradient Descent ([gradient_descent.ipynb](gradient_descent.ipynb))

ğŸ¯ This project demonstrates optimization of two functions:
- ğŸ“Š Simple quadratic function: $$f(x) = xÂ² + yÂ²$$
- ğŸŒŠ Complex trigonometric function: $$f(x) = sin(1/2 * x^2 - 1/4 * y^2 + 3) * cos(2*x + 1 - e^y)$$

âš™ï¸ The optimization uses gradient descent with manually specified partial derivatives for each term.

### ğŸ”¹ Feed-Forward Networks in NumPy ([FFN_numpy.py](FFN_numpy.py))

ğŸ”¬ A pure NumPy implementation of feed-forward neural networks, demonstrating the fundamentals of forward and backward propagation without relying on deep learning frameworks.

### ğŸ”¹ Two-Layer Feed-Forward Network ([FFN_numpy_2_layers.py](FFN_numpy_2_layers.py))

ğŸ—ï¸ An extension of the NumPy implementation that specifically focuses on a two-layer architecture, providing a clear illustration of multi-layer perceptrons.

### ğŸ”¹ Feed-Forward Networks in PyTorch ([FFN_torch.py](FFN_torch.py))

ğŸ”¥ A PyTorch implementation of feed-forward networks that demonstrates how to leverage a modern deep learning framework while maintaining an understanding of the underlying concepts.

### ğŸ”¹ Recurrent Neural Networks in PyTorch ([RNN_torch.py](RNN_torch.py))

â±ï¸ Implementation of recurrent neural networks using PyTorch, exploring sequence modeling and the handling of temporal data.

## ğŸš€ Getting Started

To run these projects, you'll need Python with NumPy and PyTorch installed:

```bash
pip install numpy torch matplotlib jupyter
```